{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyN9/lDlfpQe0opDerIyx063"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# In questoo notebook carico tutto il dataset pre-processato in un dataframe pyspark\n","# successivamente vado a creare un file per ogni utente con tutte le righe(email) dove esso compare come mittente o destinatario"],"metadata":{"id":"7Af9R7zujokx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqDCyoIShb2X","executionInfo":{"status":"ok","timestamp":1691307987915,"user_tz":-120,"elapsed":18985,"user":{"displayName":"gabriele morelli","userId":"10377196500982764207"}},"outputId":"981278a4-a7bb-4e95-dd00-9a633499c03e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","source":["# Install pyspark\n","!pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0gknv_bNwIb","executionInfo":{"status":"ok","timestamp":1691308028902,"user_tz":-120,"elapsed":40997,"user":{"displayName":"gabriele morelli","userId":"10377196500982764207"}},"outputId":"7a8be480-72db-4006-e07f-ac38c69c8f6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285397 sha256=a7f5a797e3f8fad1e3a1cdad086deef48a1701ed08cc9fc3871de4007183f426\n","  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.4.1\n"]}]},{"cell_type":"code","source":["# Carico tutti i dataset dentro un dataframe pyspark\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.sql.types import StructType, StringType\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","# 1) Create a SparkSession\n","spark = SparkSession.builder.appName(\"CSVtoCHUNK\").config(\"spark.driver.memory\", \"16g\").getOrCreate()\n","\n","# 2) spark dataframe\n","df_email_spark = None\n","\n","folder_path = '/content/gdrive/MyDrive/processati_email'\n","\n","i=0\n","\n","for filename in os.listdir(folder_path):\n","\n","    if filename.startswith('email_') and filename.endswith('.csv'):\n","        i=i+1\n","        file_path = os.path.join(folder_path, filename)\n","\n","        #read the CSV files into temporary Spark DataFrames (temp_df),\n","        # and append them to df_email_spark using the union method\n","        temp_df = spark.read.csv(file_path, header=True, inferSchema=True)\n","\n","        if df_email_spark is None:\n","            df_email_spark = temp_df\n","            print(i , ' FILE caricato:', filename)# , ', righe:', df_email_spark.count())\n","        else:\n","            df_email_spark = df_email_spark.union(temp_df)\n","            print(i , ' FILE caricato:', filename)# , ':', df_email_spark.count())\n","\n","\n","#df_email_spark.show()\n","#print('dataset completo: ', df_email_spark.count())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYj2nBLjIf4o","executionInfo":{"status":"ok","timestamp":1691308249958,"user_tz":-120,"elapsed":221068,"user":{"displayName":"gabriele morelli","userId":"10377196500982764207"}},"outputId":"bd1316e0-133e-4dba-e66b-b903f3152433"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1  FILE caricato: email_60-79.csv\n","2  FILE caricato: email_0-19.csv\n","3  FILE caricato: email_20-39.csv\n","4  FILE caricato: email_80-99.csv\n","5  FILE caricato: email_40-59.csv\n","6  FILE caricato: email_100-119.csv\n","7  FILE caricato: email_120-139.csv\n","8  FILE caricato: email_180-199.csv\n","9  FILE caricato: email_160-179.csv\n","10  FILE caricato: email_140-159.csv\n","11  FILE caricato: email_220-239.csv\n","12  FILE caricato: email_240-259.csv\n","13  FILE caricato: email_200-219.csv\n","14  FILE caricato: email_260-279.csv\n","15  FILE caricato: email_280-299.csv\n","16  FILE caricato: email_300-319.csv\n","17  FILE caricato: email_340-359.csv\n","18  FILE caricato: email_360-379.csv\n","19  FILE caricato: email_320-339.csv\n","20  FILE caricato: email_400-419.csv\n","21  FILE caricato: email_380-399.csv\n","22  FILE caricato: email_440-459.csv\n","23  FILE caricato: email_420-439.csv\n","24  FILE caricato: email_480-500.csv\n","25  FILE caricato: email_460-479.csv\n"]}]},{"cell_type":"code","source":[" df_anagrafici_excel = pd.read_excel(io = \"/content/gdrive/MyDrive/Colab Notebooks/Dati per POLIMI RIVISTO_OUTPUT.xlsx\", engine='openpyxl', sheet_name= 'OUTPUT')\n","\n"," df_ID = df_anagrafici_excel['CODICI RISPONDENTI'].unique().tolist()\n","\n"," print(len(df_ID))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1FQ-w3Mb1AYb","executionInfo":{"status":"ok","timestamp":1691308356897,"user_tz":-120,"elapsed":1592,"user":{"displayName":"gabriele morelli","userId":"10377196500982764207"}},"outputId":"83f18f19-91ac-40e2-a6c8-b7341375b2c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2041\n"]}]},{"cell_type":"code","source":["# Here I take all the rows from the whole dataset where the user apper as a sender or as a receiver and I create a new file for each user.\n","\n","csv_file_path = '/content/gdrive/MyDrive/processati_email/chunked_userID/'\n","\n","print(len(df_ID))\n","print()\n","\n","\n","for  user_id in df_ID:\n","    #if index< 2034 : continue\n","    #if index== 200 : break\n","\n","    #user_id = row['user_id']\n","    if ( (user_id==\"ND\")|(user_id==\"Consulenti\")|(user_id==\"External\") ): continue\n","    #print(index, ' ', user_id)\n","    #if user_id not in ['sWEUn-hRT1SjyBqfdlTDsg', 'FgTv82gESKu4DfVY0F435w', 'XdBe3NO6T0edHWEfoKChpg', 'Lstjqws8S86YulPOxOP4Mw', '60bCgQeiQ_iQ6B6X2sRsBg', 'ZEQWsofySoOFuU3ebdxpRA', 'hPx21qzXQaSJjaBuMWrehA', 'nmSPsaCBSuOVb2y0Erm-Sw' ] : continue\n","\n","    # Create the temporary DataFrame \"df_temp\" containing rows with matching \"user_id\"\n","    df_temp = df_email_spark.filter((F.col(\"source_from_header_address\") == user_id) | (F.col(\"destination_address\") == user_id))\n","\n","    pandas_df_temp = df_temp.toPandas()\n","    csv_filename = f\"{user_id}.csv\"\n","\n","    pandas_df_temp.to_csv(os.path.join(csv_file_path, csv_filename), header=True, index=False)\n","\n","    #print(f\"'{index}' DataFrame for user_id '{user_id}' saved as '{csv_filename}'.\")\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYxMWRM4Yy7i","executionInfo":{"status":"ok","timestamp":1691309669852,"user_tz":-120,"elapsed":915188,"user":{"displayName":"gabriele morelli","userId":"10377196500982764207"}},"outputId":"c94a52a9-1dac-411d-99ac-0991db4e1cf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2041\n","\n"]}]}]}